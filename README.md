# Robust door detection in autonomous mobile robots

This repository contains my master's thesis, entitled *Robust door detection in autonomous mobile robots*. The aim of this project is to build a detector that is able to recognize the doors. The project is composed by two main phases: data collection and detector construction.

- **Data collection:** The data collection phase is a fundamental part of this thesis. The dataset is collected using [Gibson](http://gibsonenv.stanford.edu/), a virtualization framework that simulates 3D worlds, the physics that characterizes the real world, and some different robot types to explore these environments. *Gibson*, during the exploration phase, provides three different types of data: RGB images, depth data, and semantic images. The semantic images are used as ground truth: the pixels' color changes according to the object they belong to. In this way, it is possible to find objects (doors in this case) inside the RGB and depth data. To have semantic information, the worlds must be properly annotated. This is not the case of Gibson's standard worlds database (which makes it possible to obtain only visual and depth data). The semantically annotated worlds come from [Stanford2D3Ds](https://github.com/alexsax/2D-3D-Semantics) and [Matterport3D](https://niessner.github.io/Matterport/). The collected dataset is composed of RGB images, depth data, semantic images and the robot pose in the environment. Since the navigation of a simulated autonomous agent is difficult because the worlds' 3D structure is inaccurate, a modified version of Gibson (available [here](https://github.com/micheleantonazzi/GibsonEnv.git)) is used to collect data. This upgraded version provides a new simulation mode: all physical constraints are deleted and the robot can be moved and rotated in the space at each simulation stage.
- **Detector construction:** in the second phase the data collected are used to train an end-to-end classifier to detect doors.

