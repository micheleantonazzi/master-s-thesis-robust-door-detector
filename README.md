# Robust door detection in autonomous mobile robots

This repository contains my master's thesis, entitled *Robust door detection in autonomous mobile robots*. The aim of this project is to build a door detector. The project is composed of two main phases: data collection and detector fine-tune.

- **Data collection:** The data collection phase is a fundamental part of this thesis. The dataset is collected using [Gibson](http://gibsonenv.stanford.edu/) and [gibson-env-utilities](https://github.com/micheleantonazzi/gibson-env-utilities) (a package to easily use it). Gibson is a virtualization framework that simulates 3D worlds, the physics that characterizes the real world, and some different robot types to explore these environments. *Gibson* provides three different types of data: RGB images, depth data, and semantic images. The semantic images represents the ground truth: the pixels' color changes according to the object they belong to. In this way, it is possible to find objects (doors in this case) inside the RGB and depth data. The semantically annotated worlds come from [Stanford2D3Ds](https://github.com/alexsax/2D-3D-Semantics) and [Matterport3D](https://niessner.github.io/Matterport/). The collected dataset is composed of RGB images, depth data, semantic images and the robot pose in the environment. Since the navigation of a simulated autonomous agent is difficult because the worlds' 3D structure is inaccurate, a modified version of Gibson (available [here](https://github.com/micheleantonazzi/GibsonEnv.git)) is used to collect data. This upgraded version provides a new simulation mode: all physical constraints are deleted and the robot can be moved and rotated in the space at each simulation stage.
- **Detector fine-tune:** in the second phase the data collected are used to fine tune [DETR](https://arxiv.org/abs/2005.12872), an end-to-end object detector.

