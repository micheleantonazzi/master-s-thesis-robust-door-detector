@misc{surveydeeplimits,
      title={The Limits and Potentials of Deep Learning for Robotics}, 
      author={Niko Sünderhauf and Oliver Brock and Walter Scheirer and Raia Hadsell and Dieter Fox and Jürgen Leitner and Ben Upcroft and Pieter Abbeel and Wolfram Burgard and Michael Milford and Peter Corke},
      year={2018},
      eprint={1804.06557},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}
@article{sonarandivisualdoordetection,
	title = {Learning to traverse doors using visual information},
	journal = {Mathematics and Computers in Simulation},
	volume = {60},
	number = {3},
	pages = {347-356},
	year = {2002},
	note = {Intelligent Forecasting, Fault Diagnosis, Scheduling, and Control},
	issn = {0378-4754},
	doi = {https://doi.org/10.1016/S0378-4754(02)00027-7},
	url = {https://www.sciencedirect.com/science/article/pii/S0378475402000277},
	author = {Iñaki Monasterio and Elena Lazkano and Iñaki Rañó and Basilo Sierra},
	keywords = {Door traversing behavior, Mobile robots, Neural networks, Visual door detection},
	abstract = {Mobile robots need to navigate in their environment in order to perform useful tasks. Doors appear in almost every office-like indoor environment and they have to be crossed often during the navigation process. We present in this paper a new approach that uses visual information to anticipate that a door has to be crossed. Combining then visual information with ultrasonic sensors, the robot approaches the door until an adequate distance is reached. Door traversing is then performed using sonar sensors. This paper describes the control architecture and the behaviors that have been implemented to obtain the door traversing behavior. Results and performance issues are explained. The experiments have been carried out with a B21 mobile robot.}
}

@INPROCEEDINGS{edgeandcornerdoorsdetector,
	author={Yang, Xiaodong and Tian, Yingli},
	booktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops}, 
	title={Robust door detection in unfamiliar environments by combining edge and corner features}, 
	year={2010},
	volume={},
	number={},
	pages={57-64},
	doi={10.1109/CVPRW.2010.5543830}}

@ARTICLE{canny,
	author={Canny, John},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={A Computational Approach to Edge Detection}, 
	year={1986},
	volume={PAMI-8},
	number={6},
	pages={679-698},
	doi={10.1109/TPAMI.1986.4767851}}

@article{cornerdetector,
	author = {Xiaochen He and Nelson Hon Ching Yung},
	title = {{Corner detector based on global and local curvature properties}},
	volume = {47},
	journal = {Optical Engineering},
	number = {5},
	publisher = {SPIE},
	pages = {1 -- 12},
	keywords = {corner detection, adaptive threshold, region of support, curvature, contour, round corner, obtuse corner, Sensors, Corner detection, Detection and tracking algorithms, Optical engineering, Edge detection, Quantization, Sensor performance, Feature extraction, Image segmentation, Roads},
	year = {2008},
	doi = {10.1117/1.2931681},
	URL = {https://doi.org/10.1117/1.2931681}
}

@article{computervisionsurvey,
	author    = {Zhengxia Zou and
	Zhenwei Shi and
	Yuhong Guo and
	Jieping Ye},
	title     = {Object Detection in 20 Years: {A} Survey},
	journal   = {CoRR},
	volume    = {abs/1905.05055},
	year      = {2019},
	url       = {http://arxiv.org/abs/1905.05055},
	eprinttype = {arXiv},
	eprint    = {1905.05055},
	timestamp = {Tue, 28 May 2019 12:48:08 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1905-05055.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{rcnn,
	author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	title = {Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2014}
}

@ARTICLE{fasterrcnn,
	author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}, 
	year={2017},
	volume={39},
	number={6},
	pages={1137-1149},
	doi={10.1109/TPAMI.2016.2577031}}

@ARTICLE{sppnet,
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition}, 
	year={2015},
	volume={37},
	number={9},
	pages={1904-1916},
	doi={10.1109/TPAMI.2015.2389824}}

@article{fastrcnn,
	author    = {Ross B. Girshick},
	title     = {Fast {R-CNN}},
	journal   = {CoRR},
	volume    = {abs/1504.08083},
	year      = {2015},
	url       = {http://arxiv.org/abs/1504.08083},
	eprinttype = {arXiv},
	eprint    = {1504.08083},
	timestamp = {Mon, 13 Aug 2018 16:49:11 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/Girshick15.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{yolo,
	author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	title = {You Only Look Once: Unified, Real-Time Object Detection},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2016}
}

@article{yolov2,
	title={YOLO9000: Better, Faster, Stronger},
	author={Redmon, Joseph and Farhadi, Ali},
	journal={arXiv preprint arXiv:1612.08242},
	year={2016}
}

@article{yolov3,
	title={YOLOv3: An Incremental Improvement},
	author={Redmon, Joseph and Farhadi, Ali},
	journal = {arXiv},
	year={2018}
}

@InProceedings{ssd,
	author="Liu, Wei
	and Anguelov, Dragomir
	and Erhan, Dumitru
	and Szegedy, Christian
	and Reed, Scott
	and Fu, Cheng-Yang
	and Berg, Alexander C.",
	editor="Leibe, Bastian
	and Matas, Jiri
	and Sebe, Nicu
	and Welling, Max",
	title="SSD: Single Shot MultiBox Detector",
	booktitle="Computer Vision -- ECCV 2016",
	year="2016",
	publisher="Springer International Publishing",
	address="Cham",
	pages="21--37",
	abstract="We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. SSD is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stages and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, COCO, and ILSVRC datasets confirm that SSD has competitive accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. For {\$}{\$}300 {\backslash}times 300{\$}{\$}300{\texttimes}300input, SSD achieves 74.3 {\%} mAP on VOC2007 test at 59 FPS on a Nvidia Titan X and for {\$}{\$}512 {\backslash}times 512{\$}{\$}512{\texttimes}512input, SSD achieves 76.9 {\%} mAP, outperforming a comparable state of the art Faster R-CNN model. Compared to other single stage methods, SSD has much better accuracy even with a smaller input image size. Code is available at https://github.com/weiliu89/caffe/tree/ssd.",
	isbn="978-3-319-46448-0"
}

@article{focalloss,
	author    = {Tsung{-}Yi Lin and
	Priya Goyal and
	Ross B. Girshick and
	Kaiming He and
	Piotr Doll{\'{a}}r},
	title     = {Focal Loss for Dense Object Detection},
	journal   = {CoRR},
	volume    = {abs/1708.02002},
	year      = {2017},
	url       = {http://arxiv.org/abs/1708.02002},
	eprinttype = {arXiv},
	eprint    = {1708.02002},
	timestamp = {Mon, 13 Aug 2018 16:46:12 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1708-02002.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}