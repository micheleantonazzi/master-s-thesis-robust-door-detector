@article{imagenetclassification,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	title = {ImageNet Classification with Deep Convolutional Neural Networks},
	year = {2017},
	issue_date = {June 2017},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {60},
	number = {6},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/3065386},
	doi = {10.1145/3065386},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.},
	journal = {Commun. ACM},
	month = {may},
	pages = {84–90},
	numpages = {7}
}


@article{pca,
	title = {Principal components analysis (PCA)},
	journal = {Computers \& Geosciences},
	volume = {19},
	number = {3},
	pages = {303-342},
	year = {1993},
	issn = {0098-3004},
	doi = {https://doi.org/10.1016/0098-3004(93)90090-R},
	author = {Andrzej Maćkiewicz and Waldemar Ratajczak},
	keywords = {Principal Components Analysis, Variance-covariance matrix, Coefficients of determination, Eigenvalues, Eigenvectors, Correlation matrix, Bartlett's statistics, FORTRAN 77}
}

@inproceedings{sne,
	title={Stochastic neighbor embedding},
	author={Hinton, Geoffrey and Roweis, Sam T},
	booktitle={Annual conference on Neural Information Processing Systems - (NIPS)},
	volume={15},
	pages={833--840},
	year={2002},
	organization={Citeseer}
}

@article{tsne,
	author = {van der Maaten, Laurens and Hinton, Geoffrey},
	year = {2008},
	month = {11},
	pages = {2579-2605},
	title = {Viualizing data using t-SNE},
	volume = {9},
	journal = {Journal of Machine Learning Research}
}

@article{deepdoors2,
	author = {Ramôa, João and Lopes, Vasco and Alexandre, Luís and Mogo, Sandra},
	year = {2021},
	month = {05},
	pages = {},
	title = {Real-time 2D–3D door detection and state classification on a low-power device},
	volume = {3},
	journal = {SN Applied Sciences},
	doi = {10.1007/s42452-021-04588-3}
}

@INPROCEEDINGS{deepdoors1,
	author={Ramôa, João Gaspar and Alexandre, Luís A. and Mogo, S.},
	booktitle={2020 IEEE International Conference on Autonomous Robot Systems and Competitions - (ICARSC)}, 
	title={Real-Time 3D Door Detection and Classification on a Low-Power Device}, 
	year={2020},
	volume={},
	number={},
	pages={96-101},
	doi={10.1109/ICARSC49921.2020.9096155}}

@misc{detectron2,
	author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and
	Wan-Yen Lo and Ross Girshick},
	title =        {Detectron2},
	howpublished = {\url{https://github.com/facebookresearch/detectron2}},
	year =         {2019}
}

@misc{adamw,
	author    = {Ilya Loshchilov and
	Frank Hutter},
	title     = {Fixing Weight Decay Regularization in Adam},
	journal   = {CoRR},
	volume    = {abs/1711.05101},
	year      = {2017},
	eprinttype = {arXiv},
	eprint    = {1711.05101},
	timestamp = {Mon, 13 Aug 2018 16:48:18 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1711-05101.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{fullyconvolutional,
	title={Fully convolutional instance-aware semantic segmentation},
	author={Li, Yi and Qi, Haozhi and Dai, Jifeng and Ji, Xiangyang and Wei, Yichen},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition - (CVPR)},
	pages={2359--2367},
	year={2017}
}

@book{averageprecision,
	author = {Salton, Gerard and McGill, Michael J.},
	title = {Introduction to Modern Information Retrieval},
	year = {1986},
	isbn = {0070544840},
	publisher = {McGraw-Hill, Inc.},
	address = {USA}
}

@inproceedings{delaunayproof,
	title={A short proof of the toughness of Delaunay triangulations},
	author={Biniaz, Ahmad},
	booktitle={Symposium on Simplicity in Algorithms},
	pages={43--46},
	year={2020},
	organization={SIAM}
}

@misc{repeatabilityslamarxiv,
	title={Predicting Performance of SLAM Algorithms}, 
	author={Matteo Luperto and Valerio Castelli and Francesco Amigoni},
	year={2021},
	eprint={2109.02329},
	archivePrefix={arXiv},
	primaryClass={cs.RO}
}

@inproceedings{repeatabilityslam,
	title={Improving repeatability of experiments by automatic evaluation of slam algorithms},
	author={Amigoni, Francesco and Castelli, Valerio and Luperto, Matteo},
	booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems - (IROS)},
	pages={7237--7243},
	year={2018},
	organization={IEEE}
}

@INPROCEEDINGS{frontierexploration,
	author={Yamauchi, B.},
	booktitle={Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97. 'Towards New Computational Principles for Robotics and Automation'}, 
	title={A frontier-based approach for autonomous exploration}, 
	year={1997},
	volume={},
	number={},
	pages={146-151},
	doi={10.1109/CIRA.1997.613851}}

@online{husky,
	author = {Clearpath Robotics},
	title = {Husky UGV},
	url = {http://wiki.ros.org/Robots/Husky},
	urldate = {2021-11-11}
}

@online{turtlebot2,
	author = {Robotis},
	title = {Turtlebot2},
	url = {http://wiki.ros.org/Robots/TurtleBot},
	urldate = {2021-11-11}
}

@online{turtlebot3,
	author = {Robotis},
	title = {Turtlebot3},
	url = {http://wiki.ros.org/turtlebot3},
	urldate = {2021-11-11}
}

@inproceedings{scannet,
	title={Scannet: Richly-annotated 3d reconstructions of indoor scenes},
	author={Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
	booktitle={Proceedings of the IEEE Conference on Computer Cision and Pattern Recognition -(CVPR)},
	pages={5828--5839},
	year={2017}
}

@inproceedings{topologyurban,
	author    = {Emily Whiting and Jonathan Battat and Seth Teller},
	title     = {Topology of Urban Environments},
	booktitle = {Computer-Aided Architectural Design Futures (CAADFutures)},
	year      = {2007},
	location  = {Sydney, Australia},
	pages     = {114--128},
	publisher = {Springer}
}

@article{surveydeeplimits,
	title={The limits and potentials of deep learning for robotics},
	author={S{\"u}nderhauf, Niko and Brock, Oliver and Scheirer, Walter and Hadsell, Raia and Fox, Dieter and Leitner, J{\"u}rgen and Upcroft, Ben and Abbeel, Pieter and Burgard, Wolfram and Milford, Michael and others},
	journal={The International Journal of Robotics Research},
	volume={37},
	number={4-5},
	pages={405--420},
	year={2018},
	publisher={SAGE Publications Sage UK: London, England}
}

@article{sonarandivisualdoordetection,
	title = {Learning to traverse doors using visual information},
	journal = {Mathematics and Computers in Simulation},
	volume = {60},
	number = {3},
	pages = {347-356},
	year = {2002},
	note = {Intelligent Forecasting, Fault Diagnosis, Scheduling, and Control},
	issn = {0378-4754},
	doi = {https://doi.org/10.1016/S0378-4754(02)00027-7},
	author = {Iñaki Monasterio and Elena Lazkano and Iñaki Rañó and Basilo Sierra},
	keywords = {Door traversing behavior, Mobile robots, Neural networks, Visual door detection},
	abstract = {Mobile robots need to navigate in their environment in order to perform useful tasks. Doors appear in almost every office-like indoor environment and they have to be crossed often during the navigation process. We present in this paper a new approach that uses visual information to anticipate that a door has to be crossed. Combining then visual information with ultrasonic sensors, the robot approaches the door until an adequate distance is reached. Door traversing is then performed using sonar sensors. This paper describes the control architecture and the behaviors that have been implemented to obtain the door traversing behavior. Results and performance issues are explained. The experiments have been carried out with a B21 mobile robot.}
}

@INPROCEEDINGS{edgeandcornerdoorsdetector,
	author={Yang, Xiaodong and Tian, Yingli},
	booktitle={2010 IEEE CVPR - Workshops}, 
	title={Robust door detection in unfamiliar environments by combining edge and corner features}, 
	year={2010},
	volume={},
	number={},
	pages={57-64},
	doi={10.1109/CVPRW.2010.5543830}}

@ARTICLE{canny,
	author={Canny, John},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={A Computational Approach to Edge Detection}, 
	year={1986},
	volume={PAMI-8},
	number={6},
	pages={679-698},
	doi={10.1109/TPAMI.1986.4767851}}

@article{cornerdetector,
	author = {Xiaochen He and Nelson Hon Ching Yung},
	title = {{Corner detector based on global and local curvature properties}},
	volume = {47},
	journal = {Optical Engineering},
	number = {5},
	publisher = {SPIE},
	pages = {1 -- 12},
	keywords = {corner detection, adaptive threshold, region of support, curvature, contour, round corner, obtuse corner, Sensors, Corner detection, Detection and tracking algorithms, Optical engineering, Edge detection, Quantization, Sensor performance, Feature extraction, Image segmentation, Roads},
	year = {2008},
	doi = {10.1117/1.2931681},
}

@misc{computervisionsurvey,
	author    = {Zhengxia Zou and
	Zhenwei Shi and
	Yuhong Guo and
	Jieping Ye},
	title     = {Object Detection in 20 Years: {A} Survey},
	journal   = {CoRR},
	volume    = {abs/1905.05055},
	year      = {2019},
	eprinttype = {arXiv},
	eprint    = {1905.05055},
	timestamp = {Tue, 28 May 2019 12:48:08 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1905-05055.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{rcnn,
	author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	title = {Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2014}
}

@ARTICLE{fasterrcnn,
	author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence - (TPAMI)}, 
	title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}, 
	year={2017},
	volume={39},
	number={6},
	pages={1137-1149},
	doi={10.1109/TPAMI.2016.2577031}}

@ARTICLE{sppnet,
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition}, 
	year={2015},
	volume={37},
	number={9},
	pages={1904-1916},
	doi={10.1109/TPAMI.2015.2389824}}

@inproceedings{fastrcnn,
	title={Fast R-CNN},
	author={Girshick, Ross},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision - (ICCV)},
	pages={1440--1448},
	year={2015}
}

@InProceedings{yolo,
	author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	title = {You Only Look Once: Unified, Real-Time Object Detection},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition - (CVPR)},
	month = {June},
	year = {2016}
}

@InProceedings{yolov2,
	author = {Redmon, Joseph and Farhadi, Ali},
	title = {YOLO9000: Better, Faster, Stronger},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition - (CVPR)},
	month = {July},
	year = {2017}
}

@inproceedings{yolov3,
	title={Yolov3: An incremental improvement},
	author={Farhadi, Ali and Redmon, Joseph},
	booktitle={Computer Vision and Pattern Recognition - (CVPR)},
	pages={1804--2767},
	year={2018},
	organization={Springer Berlin/Heidelberg, Germany}
}

@InProceedings{ssd,
	author="Liu, Wei
	and Anguelov, Dragomir
	and Erhan, Dumitru
	and Szegedy, Christian
	and Reed, Scott
	and Fu, Cheng-Yang
	and Berg, Alexander C.",
	editor="Leibe, Bastian
	and Matas, Jiri
	and Sebe, Nicu
	and Welling, Max",
	title="SSD: Single Shot MultiBox Detector",
	booktitle="European Conference on Computer Vision -- (ECCV) 2016",
	year="2016",
	publisher="Springer International Publishing",
	address="Cham",
	pages="21--37",
	abstract="We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. SSD is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stages and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, COCO, and ILSVRC datasets confirm that SSD has competitive accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. For {\$}{\$}300 {\backslash}times 300{\$}{\$}300{\texttimes}300input, SSD achieves 74.3 {\%} mAP on VOC2007 test at 59 FPS on a Nvidia Titan X and for {\$}{\$}512 {\backslash}times 512{\$}{\$}512{\texttimes}512input, SSD achieves 76.9 {\%} mAP, outperforming a comparable state of the art R-CNN model. Compared to other single stage methods, SSD has much better accuracy even with a smaller input image size. Code is available at https://github.com/weiliu89/caffe/tree/ssd.",
	isbn="978-3-319-46448-0"
}

@inproceedings{focalloss,
	title={Focal loss for dense object detection},
	author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={2980--2988},
	year={2017}
}

@inproceedings{transformer,
	title={Attention is all you need},
	author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	booktitle={Advances in neural information processing systems},
	pages={5998--6008},
	year={2017}
}

@misc{surveytransformer,
	author    = {Salman H. Khan and
	Muzammal Naseer and
	Munawar Hayat and
	Syed Waqas Zamir and
	Fahad Shahbaz Khan and
	Mubarak Shah},
	title     = {Transformers in Vision: {A} Survey},
	journal   = {CoRR},
	volume    = {abs/2101.01169},
	year      = {2021},
	eprinttype = {arXiv},
	eprint    = {2101.01169},
	timestamp = {Thu, 17 Jun 2021 18:15:55 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2101-01169.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{detr,
	author="Carion, Nicolas
	and Massa, Francisco
	and Synnaeve, Gabriel
	and Usunier, Nicolas
	and Kirillov, Alexander
	and Zagoruyko, Sergey",
	editor="Vedaldi, Andrea
	and Bischof, Horst
	and Brox, Thomas
	and Frahm, Jan-Michael",
	title="End-to-End Object Detection with Transformers",
	booktitle="European Conference on Computer Vision -- (ECCV) 2020",
	year="2020",
	publisher="Springer International Publishing",
	address="Cham",
	pages="213--229",
	abstract="We present a new method that views object detection as a direct set prediction problem. Our approach streamlines the detection pipeline, effectively removing the need for many hand-designed components like a non-maximum suppression procedure or anchor generation that explicitly encode our prior knowledge about the task. The main ingredients of the new framework, called DEtection TRansformer or DETR, are a set-based global loss that forces unique predictions via bipartite matching, and a transformer encoder-decoder architecture. Given a fixed small set of learned object queries, DETR reasons about the relations of the objects and the global image context to directly output the final set of predictions in parallel. The new model is conceptually simple and does not require a specialized library, unlike many other modern detectors. DETR demonstrates accuracy and run-time performance on par with the well-established and highly-optimized Faster R-CNN baseline on the challenging COCO object detection dataset. Moreover, DETR can be easily generalized to produce panoptic segmentation in a unified manner. We show that it significantly outperforms competitive baselines. Training code and pretrained models are available at https://github.com/facebookresearch/detr.",
	isbn="978-3-030-58452-8"
}

@article{detectdoorsfeature,
	author = { G.   Cicirelli  and  T.   D'orazio  and  A.   Distante },
	title = {Target recognition by components for mobile robot navigation},
	journal = {Journal of Experimental \& Theoretical Artificial Intelligence},
	volume = {15},
	number = {3},
	pages = {281-297},
	year  = {2003},
	publisher = {Taylor \& Francis},
	doi = {10.1080/0952813021000039430},
}

@INPROCEEDINGS{doorcabinet,
	author={Llopart, Adrian and Ravn, Ole and Andersen, Nils. A.},
	booktitle={2017 3rd International Conference on Control, Automation and Robotics - (ICCAR)}, 
	title={Door and cabinet recognition using Convolutional Neural Nets and real-time method fusion for handle detection and grasping}, 
	year={2017},
	volume={},
	number={},
	pages={144-149},
	doi={10.1109/ICCAR.2017.7942676}}

@INPROCEEDINGS{doorsandnavigation,
	author={Chen, Wei and Qu, Ting and Zhou, Yimin and Weng, Kaijian and Wang, Gang and Fu, Guoqiang},
	booktitle={2014 IEEE International Conference on Robotics and Biomimetics - (ROBIO 2014)}, 
	title={Door recognition and deep learning algorithm for visual based robot navigation}, 
	year={2014},
	volume={},
	number={},
	pages={1793-1798},
	doi={10.1109/ROBIO.2014.7090595}}

@InProceedings{coco,
	author="Lin, Tsung-Yi
	and Maire, Michael
	and Belongie, Serge
	and Hays, James
	and Perona, Pietro
	and Ramanan, Deva
	and Doll{\'a}r, Piotr
	and Zitnick, C. Lawrence",
	editor="Fleet, David
	and Pajdla, Tomas
	and Schiele, Bernt
	and Tuytelaars, Tinne",
	title="Microsoft COCO: Common Objects in Context",
	booktitle="European Conference on Computer Vision -- (ECCV) 2014",
	year="2014",
	publisher="Springer International Publishing",
	address="Cham",
	pages="740--755",
	abstract="We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.",
	isbn="978-3-319-10602-1"
}

@article{pascal,
	title={The Pascal Visual Object Classes (VOC) Challenge},
	author={Mark Everingham and Luc Van Gool and Christopher K. I. Williams and John M. Winn and Andrew Zisserman},
	journal={International Journal of Computer Vision},
	year={2009},
	volume={88},
	pages={303-338}
}

@INPROCEEDINGS{humanoid,
	author={Kwak, Nosan and Arisumi, Hitoshi and Yokoi, Kazuhito},
	booktitle={2011 IEEE International Conference on Robotics and Automation - (ICRA)}, 
	title={Visual recognition of a door and its knob for a humanoid robot}, 
	year={2011},
	volume={},
	number={},
	pages={2079-2084},
	doi={10.1109/ICRA.2011.5979608}}

@inproceedings{gibson,
	title={Gibson env: Real-world perception for embodied agents},
	author={Xia, Fei and Zamir, Amir R and He, Zhiyang and Sax, Alexander and Malik, Jitendra and Savarese, Silvio},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition - (CVPR)},
	pages={9068--9079},
	year={2018}
}


@misc{igibson,
	author    = {Bokui Shen and
	Fei Xia and
	Chengshu Li and
	Roberto Mart{\'{\i}}n{-}Mart{\'{\i}}n and
	Linxi Fan and
	Guanzhi Wang and
	Shyamal Buch and
	Claudia D'Arpino and
	Sanjana Srivastava and
	Lyne P. Tchapmi and
	Micael E. Tchapmi and
	Kent Vainio and
	Li Fei{-}Fei and
	Silvio Savarese},
	title     = {iGibson, a Simulation Environment for Interactive Tasks in Large Realistic
	Scenes},
	journal   = {CoRR},
	volume    = {abs/2012.02924},
	year      = {2020},
	eprinttype = {arXiv},
	eprint    = {2012.02924},
	timestamp = {Wed, 09 Dec 2020 15:29:05 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2012-02924.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{habitat,
	title={Habitat: A platform for embodied ai research},
	author={Savva, Manolis and Kadian, Abhishek and Maksymets, Oleksandr and Zhao, Yili and Wijmans, Erik and Jain, Bhavana and Straub, Julian and Liu, Jia and Koltun, Vladlen and Malik, Jitendra and others},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision - (ICCV)},
	pages={9339--9347},
	year={2019}
}

@misc{stanford2d3d,
	author    = {Iro Armeni and
	Sasha Sax and
	Amir Roshan Zamir and
	Silvio Savarese},
	title     = {Joint 2D-3D-Semantic Data for Indoor Scene Understanding},
	journal   = {CoRR},
	volume    = {abs/1702.01105},
	year      = {2017},
	eprinttype = {arXiv},
	eprint    = {1702.01105},
	timestamp = {Mon, 13 Aug 2018 16:46:32 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/ArmeniSZS17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{matterport,
	author    = {Angel X. Chang and
	Angela Dai and
	Thomas A. Funkhouser and
	Maciej Halber and
	Matthias Nie{\ss}ner and
	Manolis Savva and
	Shuran Song and
	Andy Zeng and
	Yinda Zhang},
	title     = {Matterport3D: Learning from {RGB-D} Data in Indoor Environments},
	journal   = {CoRR},
	volume    = {abs/1709.06158},
	year      = {2017},
	eprinttype = {arXiv},
	eprint    = {1709.06158},
	timestamp = {Thu, 19 Aug 2021 19:45:39 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1709-06158.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{cubicasa,
	title={Cubicasa5k: A dataset and an improved multi-task model for floorplan image analysis},
	author={Kalervo, Ahti and Ylioinas, Juha and H{\"a}iki{\"o}, Markus and Karhu, Antti and Kannala, Juho},
	booktitle={Scandinavian Conference on Image Analysis - (SCIA)},
	pages={28--40},
	year={2019},
	organization={Springer}
}

@inproceedings{3dfront,
	title={3d-front: 3d furnished rooms with layouts and semantics},
	author={Fu, Huan and Cai, Bowen and Gao, Lin and Zhang, Ling-Xiao and Wang, Jiaming and Li, Cao and Zeng, Qixun and Sun, Chengyue and Jia, Rongfei and Zhao, Binqiang and others},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision - (ICCV)},
	pages={10933--10942},
	year={2021}
}

@book{imageofcity,
	publisher = {MIT Press},
	month = {November},
	author = {Kevin Lynch},
	title = {The Image of the City},
	note = {},
	year = {1960},
	url = {},
	keywords = {},
	ISBN = {9780262620017}
}

@book{wayfinding,
	title={Wayfinding: People, Signs, and Architecture},
	author={Paul Longley Arthur and Romedi Passini},
	year={1992}
}

@inproceedings{censure,
	author = {Agrawal, Motilal and Konolige, Kurt and Blas, Morten},
	year = {2008},
	month = {10},
	pages = {102-115},
	title = {CenSurE: Center Surround Extremas for Realtime Feature Detection and Matching},
	volume = {5305},
	isbn = {978-3-540-88692-1},
	journal = {ECCV LNCS},
	doi = {10.1007/978-3-540-88693-8_8}
}

@inproceedings{treefeature,
	author = {Calonder, Michael and Lepetit, Vincent and Fua, Pascal},
	year = {2008},
	month = {10},
	pages = {},
	title = {Keypoint Signatures for Fast Learning and Recognition},
	volume = {5302},
	doi = {10.1007/978-3-540-88682-2_6}
}

@article{deeplearningoverview,
	title={Deep learning for computer vision: A brief review},
	author={Voulodimos, Athanasios and Doulamis, Nikolaos and Doulamis, Anastasios and Protopapadakis, Eftychios},
	journal={Computational intelligence and neuroscience},
	volume={2018},
	year={2018},
	publisher={Hindawi}
}

@ARTICLE{gridmapnavigation,
	author={Elfes, A.},
	journal={Computer}, 
	title={Using occupancy grids for mobile robot perception and navigation}, 
	year={1989},
	volume={22},
	number={6},
	pages={46-57},
	doi={10.1109/2.30720}}

@INPROCEEDINGS{cuupancygridfirst,
	author={Moravec, H. and Elfes, A.},
	booktitle={Proceedings. 1985 IEEE International Conference on Robotics and Automation - (ICRA)}, 
	title={High resolution maps from wide angle sonar}, 
	year={1985},
	volume={2},
	number={},
	pages={116-121},
	doi={10.1109/ROBOT.1985.1087316}}

@INPROCEEDINGS{ariel,
	author={Yamauchi, B. and Schultz, A. and Adams, W.},
	booktitle={Proceedings. 1998 IEEE International Conference on Robotics and Automation - (ICRA)}, 
	title={Mobile robot exploration and map-building with continuous localization}, 
	year={1998},
	volume={4},
	number={},
	pages={3715-3720 vol.4},
	doi={10.1109/ROBOT.1998.681416}}

@INPROCEEDINGS{girdmapexploration,
	author={Yamauchi, B.},
	booktitle={Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97. 'Towards New Computational Principles for Robotics and Automation'}, 
	title={A frontier-based approach for autonomous exploration}, 
	year={1997},
	volume={},
	number={},
	pages={146-151},
	doi={10.1109/CIRA.1997.613851}}

@INPROCEEDINGS{segmentationsurvey,
	author={Bormann, Richard and Jordan, Florian and Li, Wenzhe and Hampp, Joshua and Hägele, Martin},
	booktitle={2016 IEEE International Conference on Robotics and Automation - (ICRA)}, 
	title={Room segmentation: Survey, implementation, and analysis}, 
	year={2016},
	volume={},
	number={},
	pages={1019-1026},
	doi={10.1109/ICRA.2016.7487234}}

@article{segmenationfornavigation,
	title = {Learning metric-topological maps for indoor mobile robot navigation},
	journal = {Artificial Intelligence},
	volume = {99},
	number = {1},
	pages = {21-71},
	year = {1998},
	issn = {0004-3702},
	doi = {https://doi.org/10.1016/S0004-3702(97)00078-7},
	author = {Sebastian Thrun},
	keywords = {Autonomous robots, Exploration, Mobile robots, Neural networks, Occupancy grids, Path planning, Planning, Robot mapping, Topological maps},
	abstract = {Autonomous robots must be able to learn and maintain models of their environments. Research on mobile robot navigation has produced two major paradigms for mapping indoor environments: grid-based and topological. While grid-based methods produce accurate metric maps, their complexity often prohibits efficient planning and problem solving in large-scale indoor environments. Topological maps, on the other hand, can be used much more efficiently, yet accurate and consistent topological maps are often difficult to learn and maintain in large-scale environments, particularly if momentary sensor data is highly ambiguous. This paper describes an approach that integrates both paradigms: grid-based and topological. Grid-based maps are learned using artificial neural networks and naive Bayesian integration. Topological maps are generated on top of the grid-based maps, by partitioning the latter into coherent regions. By combining both paradigms, the approach presented here gains advantages from both worlds: accuracy/consistency and efficiency. The paper gives results for autonomous exploration, mapping and operation of a mobile robot in populated multi-room environments.}
}

@INPROCEEDINGS{segmentationhumanrobot,
	author={Bormann, Richard and Jordan, Florian and Li, Wenzhe and Hampp, Joshua and Hägele, Martin},
	booktitle={2016 IEEE International Conference on Robotics and Automation - (ICRA)}, 
	title={Room segmentation: Survey, implementation, and analysis}, 
	year={2016},
	volume={},
	number={},
	pages={1019-1026},
	doi={10.1109/ICRA.2016.7487234}}

@article{segmentationcleaning,
	title={New brooms sweep clean - an autonomous robotic cleaning assistant for professional office cleaning},
	author={Richard Bormann and Joshua Hampp and Martin H{\"a}gele},
	journal={2015 IEEE International Conference on Robotics and Automation - (ICRA)},
	year={2015},
	pages={4470-4477}
}

@INPROCEEDINGS{scenerecognitionaudio,
	author={Espinace, P. and Kollar, T. and Soto, A. and Roy, N.},
	booktitle={2010 IEEE International Conference on Robotics and Automation - (ICRA)}, 
	title={Indoor scene recognition through object detection}, 
	year={2010},
	volume={},
	number={},
	pages={1406-1413},
	doi={10.1109/ROBOT.2010.5509682}}

@INPROCEEDINGS{scenerecognitiononjectdetection,
	author={Espinace, P. and Kollar, T. and Soto, A. and Roy, N.},
	booktitle={2010 IEEE International Conference on Robotics and Automation - (ICRA)}, 
	title={Indoor scene recognition through object detection}, 
	year={2010},
	volume={},
	number={},
	pages={1406-1413},
	doi={10.1109/ROBOT.2010.5509682}}

@INPROCEEDINGS{placecategorization,
	author={Sünderhauf, Niko and Dayoub, Feras and McMahon, Sean and Talbot, Ben and Schulz, Ruth and Corke, Peter and Wyeth, Gordon and Upcroft, Ben and Milford, Michael},
	booktitle={2016 IEEE International Conference on Robotics and Automation - (ICRA)}, 
	title={Place categorization and semantic mapping on a mobile robot}, 
	year={2016},
	volume={},
	number={},
	pages={5729-5736},
	doi={10.1109/ICRA.2016.7487796}}

@INPROCEEDINGS{placecategorizationlargescale,
	author={Pronobis, Andrzej and Jensfelt, Patric},
	booktitle={2012 IEEE International Conference on Robotics and Automation - (ICRA)}, 
	title={Large-scale semantic mapping and reasoning with heterogeneous modalities}, 
	year={2012},
	volume={},
	number={},
	pages={3515-3522},
	doi={10.1109/ICRA.2012.6224637}}

@ARTICLE{segmentation3d,
	author={Ambruş, Rareş and Claici, Sebastian and Wendt, Axel},
	journal={IEEE Robotics and Automation Letters - (RA-L)}, 
	title={Automatic Room Segmentation From Unstructured 3-D Data of Indoor Environments}, 
	year={2017},
	volume={2},
	number={2},
	pages={749-756},
	doi={10.1109/LRA.2017.2651939}}

@misc{semanticslamsurvey,
	title={Evaluating the Impact of Semantic Segmentation and Pose Estimation on Dense Semantic SLAM}, 
	author={Suman Raj Bista and David Hall and Ben Talbot and Haoyang Zhang and Feras Dayoub and Niko Sünderhauf},
	year={2021},
	eprint={2109.07748},
	archivePrefix={arXiv},
	primaryClass={cs.RO}
}

@InProceedings{resnet,
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	title = {Deep Residual Learning for Image Recognition},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition - (CVPR)},
	month = {June},
	year = {2016}
}

@InProceedings{hungarian,
	author = {Stewart, Russell and Andriluka, Mykhaylo and Ng, Andrew Y.},
	title = {End-To-End People Detection in Crowded Scenes},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition - (CVPR)},
	month = {June},
	year = {2016}
}

@InProceedings{generalizediou,
	author = {Rezatofighi, Hamid and Tsoi, Nathan and Gwak, JunYoung and Sadeghian, Amir and Reid, Ian and Savarese, Silvio},
	title = {Generalized Intersection Over Union: A Metric and a Loss for Bounding Box Regression},
	booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition - (CVPR)},
	month = {June},
	year = {2019}
}

@INPROCEEDINGS{imagenet,
	author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
	booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition - (CVPR)}, 
	title={ImageNet: A large-scale hierarchical image database}, 
	year={2009},
	volume={},
	number={},
	pages={248-255},
	doi={10.1109/CVPR.2009.5206848}}

@misc{verydeepimagenet,
	title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
	author={Karen Simonyan and Andrew Zisserman},
	year={2015},
	eprint={1409.1556},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}
