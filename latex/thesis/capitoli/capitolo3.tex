\chapter{Problem Formulation}
\label{capitolo3}
\thispagestyle{empty}

\section{Motivation and Goal}

As mentioned in the previous chapter, doors are useful semantic features for an active agent. Collecting information about doors, a robot improves significantly its knowledge about the environment in which it operates. Exploration and navigation, two of the main task for a mobile robot, are strongly influenced by doors, especially considering their location and status (e.g. closed or opened). During the mapping procedure, doors detection provide useful information to the robot, that are usable to improve the exploration of an unknown environment. By detecting closed doors, an agent guess that some floor areas are temporarily unreachable, and can consequentially act to collect the entire environment map. For example, it can open the door through a robotic arm or asking help to a human operator. Another solution concerns identifying the presence of unreachable locations by detecting closed door and making a map refinement in future stages (when closed doors have been opened). The map acquisition enables autonomous agents to navigate inside a previously unknown environment. Accurate knowledge of doors can be involved in the navigation strategy, improving the robot's planning algorithms and the procedure for reaching goals. Mapping and navigation have been extensively researched and several automatized tools have been proposed to solve them. However, the research community is still investigating robust methods for obtaining accurate room-level segmentation from an indoor environment. The sensors' technology is imperfect, so noise and missing data introduce several errors in robot perception. Furthermore, indoor environments are highly cluttered with furniture and other objects. Separating clutter from permanent structures such as walls and doors is difficult as furniture can occlude permanent structures. Finding doors' location can helps the semantic rooms segmentation and categorization performed autonomously by an intelligent agent. In this way, an autonomous agent builds an abstract model of the environment more informative, improving its reason abilities and strategies to exploit its assigned task. For example, in an object find activity, the robot starts searching in the room with the highest probability of finding a precise object categories.

This thesis presents a module to perform doors detection by autonomous mobile agents. Researchers propose feature based methods \cite{sonarandivisualdoordetection, humanoid, edgeandcornerdoorsdetector} and deep techniques \cite{detectdoorsfeature, doorsandnavigation, doorcabinet} for detecting door in indoor environments.  The module proposed in this work uses RGB images as input data, approaching the problem as an object detection task. Computer Vision is highly dependent on the power of deep learning and the novel transformers-based architectures for object detection obtain competitive results compared with previous techniques. Since the peculiarities of transformers have not yet been tested in a doors detection task, the proposed detector is based on DETR \cite{detr}: a deep end-to-end module that take advantages of Transformers to capture the relationships between visual features vectors extracted by a CNN backbone. 

The development and training of a deep module used in a robotic vision context has to be more general as possible. This is because, in the subsequent deployment phase, an agent operates in an unknown environment. The model's performance can greatly degrade in unfamiliar scenes, since their features and structural characteristics have not been considered during the training phase. Despite this, an autonomous agent operates in a few environment during its life cycle. Intelligent agents, like service robots or smart vacuum cleaners, are deployed in a specific environment and often operates inside it during all their life cycle. Frequently moving a robot from an scene to another is not a common scenario. Intelligent agents implement complex strategies for orienting and navigating in real environments. As robots try to understand a scene as well as possible, also artificial environments offer some feature and structural elements that helps agents' perception. Researches defined the \textit{wayfinding} principle, which encompasses all of the ways in which people (and animals) orient themselves in physical space and navigate from a place to another. Following this knowledge of how human perceive, architects design and build artificial environment that helps human to orient and navigate inside it. In \citeyear{imageofcity}, \citeauthor{imageofcity} introduced this concept in his book \citetitle{imageofcity}, where \textit{wayfinding} is defined as ``a consistent use and organization of definite sensory cues from the external environment''.  The author argue that, in the process of \textit{wayfinding}, the strategic link is the generalized mental image of the exterior physical world that is held by an individual. The coherence of the image may arise in several ways. For example, objects can be ordered or remarkable in a scene, so the user recognizes them through its previous experience and the familiarity acquired with the environment. Alternatively, an object seen for the first time may be identified because it
conforms to a stereotype already constructed by the observer in other scenes. In \citeyear{wayfinding}, the \textit{wayfinding} concepts were further expanded from \citeauthor{wayfinding} in their book entitled \citetitle{wayfinding} \cite{wayfinding}. This works describes and illustrates how people use both sings and other wayfinding cues to find their way in complex scenes, all set into practical contexts. 
Indoor environments presents a coherent design and a standardized visual aspect in order to help \textit{wayfinding} strategies used by intelligent agents. Following this intuition, in the same environment there are a few types of doors, repeated in different locations. The intuition of this thesis is to imply the \textit{wayfinding} characteristics of indoor environments (originally realized for humans) in a robotic vision task to increase the detection performance. Considering the deployment condition of mobile robots (agents operates in the same territory for a long time) and the coherent design of indoor environments, this work propose an approach for increasing the doors detector accuracy in unfamiliar environments. The main idea is to specialize the previously trained general doors detector on the specific environment in which the robot operates. This method, called \textit{one-shot incremental learning}, consists on collecting a sub-set of examples from the unfamiliar scene in which the robot will be deployed. Then, the detector is re-trained using these new environment-specific data. In this way, the doors detection module learns how to robustly recognize the new types of doors that characterize the deployment environment. Furthermore, this thesis investigates the amount of data required to achieve an acceptable increase in performance.

The power of deep learning is limited in vision robotics applications by some problems and challenges that researchers are still investigating. The datasets used in computer vision tasks are not suitable for robotic vision applications. They do not contain sufficient data to well generalize the domain they represent. Objects of the same category can look very different depending on the context in which they are use and the scene's design, so the examples must to be collected from several environment types. Due to a mobile agent can autonomously explore an area, the object images to train a deep robotic detector must be captured from different viewpoints. Furthermore, the locations from where data are acquired should be consistent with a possible exploration strategy followed by a mobile robot. In addition to datasets, even metrics used in computer vision are insufficient to evaluate an end-to-end robotic vision module. They compute an overall statics over a single dataset which often includes only positive samples (images with objects to detect). To overcome the limitations just mentioned, this thesis describes a method for acquiring a visual dataset specific for door detection in a robotics context. The examples are collected in virtualized heterogeneous environments scanned from real world. The viewpoints are chosen simulating an exploration strategy plausible for an active agent. Furthermore, this thesis proposes a novel evaluation method that considers also the negative samples (images without doors to detect).

\section{Problem Description}

Before proceeding with the detailed discussion of our work, we firstly report some definitions and concepts about the problem addressed by this thesis. In the following paragraphs, we report the types of environments from which the data come. Then, we define doors by analyzing the features that characterize them and specifying the status they can assume. At least, we delineate the ideal scenario in which an autonomous agent can benefit from the proposed method.

\subsection{Environments' Types and Characteristics}

