\chapter{Conclusions and Future Works}
\label{sec:chapter6}
\thispagestyle{empty}

In this thesis, we have addressed the task of finding doors in autonomous mobile robots. To achieve this, we proposed a doors detector based on DETR, a deep end-to-end module that performs object detection in RGB images by exploiting the capabilities of a CNN backbone (ResNet) and a Transformer. To increase the model's performance in a specific environment, we also present a technique, called \textit{one-shot incremental learning}. This paradigm is based on the observation that often a deployed robot operates in a single environment for a long time. Following the \textit{wayfinding} principle, an artificial scene presents a coherent visual aspect as well as doors of a single environment expose similar features. The one-shot incremental learning technique proposed in this thesis aims to fine-tune a general door detector with new examples to specialize the module for a specific environment. We also propose an approach to acquire a visual dataset and an evaluation metric to better measure the performance of a Deep Learning-based object detection module used by a mobile robot. 

The results show that our door detector reaches good results on the collected dataset. Our dataset allows us to evaluate the detector's performance in multiple environments and to simulate the deployment scenario considered in our work. Furthermore, we demonstrate that the one-shot incremental learning is a valid approach for increasing the detection accuracy of an end-to-end module used by a mobile robot. The results we collect show that the performance of a generic door detector strongly depends on the visual characteristics of the new environment in which it operates. The one-shot incremental learning mitigates this issue. Another interesting outcome of our experiments is that the smaller fine-tune operation we perform (considering the 25\% of examples collected in a new environment) allows obtaining the best performance improvement. 

In conclusion, we hope that this work has provided valuable insights about applying Deep Learning to Robotics considering the requirements of the typical scenarios in which autonomous agents operate. Since this thesis represents a small step into this research line, we report the most significant extensions of our work to suggest future investigations.

We collect the doors' examples in virtualized environments that do not allow an autonomous navigation of a simulated robot. Exploring other simulation technologies that allow an autonomous exploration of a mobile robot is a crucial step to collecting a more realistic dataset which better represents how a robot perceives an environment. Another important evolution of our work regards testing our approach on the field to evaluate the impact of door detection in robotic tasks, such as navigation, exploration, and planning.

The semantic information provided by the worlds' dataset is not sufficiently accurate to perform an automated labeling procedure of the visual dataset we collect. In fact, the bounding boxes of our dataset have been designed by a human operator. A primal direction for future works is to consider other worlds' datasets that expose more refined semantic information to acquire a larger and more precise visual dataset.

The proposed doors detector is built using DETR, the first end-to-end architecture that performs object detection exploiting the Transformers peculiarities. A valid extension of our work is to evaluate the performance of such a model in low-powered devices to measure its inference speed when run by a mobile robot. In addition, comparing the detection and inference performance of DETR with other well-known detectors represents a valid forward step of our work. 

The one-shot incremental learning technique we propose consists of fine-tuning a general  doors detector with new examples collected in an environment not included in the initial training phase. In the real deployment scenario, a human operator has to collect the images and label them with a visual tool to design the ground truth bounding boxes. An extension of this work consists of using the general doors detector rather than manually annotating the new examples and evaluate the performance improvement of the general doors detector fine-tuned with new image labeled by itself.

Finally, another important improvement regards the evaluation metric. We test the detector 
accuracy on positive images considering 2 labels: closed door and open door. The Computer Vision metric we use does not consider the fact in which a door is detected but with a wrong label as well as it can not consider a simpler binary classification task (door or no door). Refining the evaluation metric or using another one that considers these facts is a valid step for future researches.



